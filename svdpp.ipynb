{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Implement various SVD algos on movielens via tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-assign user id starting from 0\n",
    "user_id_dict = {} \n",
    "for user_id in df['user_id']:\n",
    "    if (user_id) not in user_id_dict.keys():\n",
    "        user_id_dict[(user_id)] = len(user_id_dict)\n",
    "\n",
    "        \n",
    "#re-assign item id starting from 0\n",
    "item_id_dict = {} \n",
    "for item_id in df['item_id']:\n",
    "    if (item_id) not in item_id_dict.keys():\n",
    "        item_id_dict[(item_id)] = len(item_id_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features X and labels y\n",
    "df2 = df.to_numpy()\n",
    "dat = df2[:,[0,1]]\n",
    "X = [[user_id_dict[(dat[i,0])], item_id_dict[(dat[i,1])]] for i in range(dat.shape[0])]\n",
    "X = np.array(X, dtype = np.int32)\n",
    "y = df2[:,2].astype(np.float32)\n",
    "y = np.expand_dims(y, 1)\n",
    "\n",
    "\n",
    "# Extract implicit features\n",
    "rated_by_user = [[] for i in range(len(user_id_dict))]\n",
    "for rate in X:\n",
    "    user = rate[0]\n",
    "    item = rate[1]\n",
    "    rated_by_user[user].append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-0.4069322 ],\n",
       "       [-0.38670728],\n",
       "       [-0.4209532 ],\n",
       "       [-0.38684046],\n",
       "       [-0.3857712 ],\n",
       "       [-0.39954796],\n",
       "       [-0.40087467],\n",
       "       [-0.35173818],\n",
       "       [-0.4200813 ],\n",
       "       [-0.39258903]], dtype=float32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vanilla SVD with global effects \n",
    "\n",
    "class Vanilla_SVD_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_features, num_users, num_items):\n",
    "        super(Vanilla_SVD_layer, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.global_bias = self.add_weight(\"global_bias\",\n",
    "                                            shape=[1, 1]\n",
    "                                          )\n",
    "        self.user_vectors = self.add_weight(\"user_vectors\",\n",
    "                                      shape=[int(self.num_users), int(self.num_features)]\n",
    "                                           )\n",
    "        self.item_vectors = self.add_weight(\"item_vectors\",\n",
    "                                      shape=[int(self.num_items), int(self.num_features)]\n",
    "                                           )\n",
    "        self.user_bias = self.add_weight(\"user_bias\",\n",
    "                                        shape=[int(self.num_users), 1]\n",
    "                                        )\n",
    "        self.item_bias = self.add_weight(\"item_bias\",\n",
    "                                        shape=[int(self.num_items), 1]\n",
    "                                        )\n",
    "\n",
    "    def call(self, input):\n",
    "        user_ids = tf.expand_dims(input[:,0],1)\n",
    "        item_ids = tf.expand_dims(input[:,1],1)\n",
    "\n",
    "        user_vectors_input = tf.gather_nd(\n",
    "        self.user_vectors, user_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        item_vectors_input = tf.gather_nd(\n",
    "        self.item_vectors, item_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        user_bias_input = tf.gather_nd(\n",
    "        self.user_bias, user_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        item_bias_input = tf.gather_nd(\n",
    "        self.item_bias, user_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        \n",
    "        pred = tf.math.reduce_sum(tf.math.multiply(user_vectors_input,item_vectors_input), axis = 1, keepdims = True)\n",
    "\n",
    "        return (pred + user_bias_input + item_bias_input +  self.global_bias)\n",
    "\n",
    "\n",
    "\n",
    "class SVD(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVD, self).__init__()\n",
    "        self.svd = Vanilla_SVD_layer(5, 10000, 10000)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.svd(inputs)\n",
    "        return (x)\n",
    "\n",
    "\n",
    "model = SVD()\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()\n",
    "])\n",
    "\n",
    "# Check if the model forward pass is working properly. \n",
    "model(X[range(10),:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"svd_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vanilla_svd_layer_2 (Vanilla multiple                  120001    \n",
      "=================================================================\n",
      "Total params: 120,001\n",
      "Trainable params: 120,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 1s 778us/step - loss: 0.5972 - root_mean_squared_error: 0.7728 - val_loss: 0.9505 - val_root_mean_squared_error: 0.9749\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 1s 736us/step - loss: 0.5971 - root_mean_squared_error: 0.7727 - val_loss: 0.9526 - val_root_mean_squared_error: 0.9760\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 1s 719us/step - loss: 0.5967 - root_mean_squared_error: 0.7724 - val_loss: 0.9539 - val_root_mean_squared_error: 0.9767\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 1s 718us/step - loss: 0.5968 - root_mean_squared_error: 0.7725 - val_loss: 0.9544 - val_root_mean_squared_error: 0.9769\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 1s 722us/step - loss: 0.5963 - root_mean_squared_error: 0.7722 - val_loss: 0.9551 - val_root_mean_squared_error: 0.9773\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 1s 709us/step - loss: 0.5963 - root_mean_squared_error: 0.7722 - val_loss: 0.9567 - val_root_mean_squared_error: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e22116410>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callback for autostopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_root_mean_squared_error', patience=5)\n",
    "\n",
    "\n",
    "# Using Vanilla SVD as Baseline Measure\n",
    "model.fit(X, y, epochs=100, batch_size=64, validation_split = 0.2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVDPP used in netflix prize\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "class SVDPP_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_features, num_users, num_items, l1 = 0, l2 = 0):\n",
    "        super(SVDPP_layer, self).__init__()\n",
    "        self._supports_ragged_inputs = True \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_features = num_features\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.global_bias = self.add_weight(\"global_bias\",\n",
    "                                           shape=[1, 1]\n",
    "                                          )\n",
    "        self.user_vectors = self.add_weight(\"user_vectors\",\n",
    "                                            shape=[int(self.num_users), int(self.num_features)],\n",
    "                                            regularizer=tf.keras.regularizers.l1_l2(l1=self.l1, l2=self.l2)\n",
    "                                           )\n",
    "        self.item_vectors = self.add_weight(\"item_vectors\",\n",
    "                                            shape=[int(self.num_items), int(self.num_features)],\n",
    "                                            regularizer=tf.keras.regularizers.l1_l2(l1=self.l1, l2=self.l2)\n",
    "                                           )\n",
    "        self.item_vectors_2 = self.add_weight(\"item_vectors_2\",\n",
    "                                              shape=[int(self.num_items), int(self.num_features)],\n",
    "                                              regularizer=tf.keras.regularizers.l1_l2(l1=self.l1, l2=self.l2)\n",
    "                                             )\n",
    "        self.user_bias = self.add_weight(\"user_bias\",\n",
    "                                         shape=[int(self.num_users + 1), 1]\n",
    "                                        )\n",
    "        self.item_bias = self.add_weight(\"item_bias\",\n",
    "                                         shape=[int(self.num_items + 1), 1]\n",
    "                                        )\n",
    "    \n",
    "    \n",
    "\n",
    "    def call(self, input):\n",
    "        user_item = input[:,0:2].to_tensor()\n",
    "        num_rated_user = tf.cast(tf.squeeze(input[:,2:3].to_tensor()), tf.float32)\n",
    "        rated_by_user = input[:,3:]\n",
    "        user_ids = tf.expand_dims(user_item[:,0],1)\n",
    "        item_ids = tf.expand_dims(user_item[:,1],1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        user_vectors_input = tf.gather_nd(\n",
    "        self.user_vectors, user_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        item_vectors_input = tf.gather_nd(\n",
    "        self.item_vectors, item_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        user_bias_input = tf.gather_nd(\n",
    "        self.user_bias, user_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        item_bias_input = tf.gather_nd(\n",
    "        self.item_bias, user_ids, batch_dims=0, name=None\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        rated_by_user = tf.expand_dims(rated_by_user,2)\n",
    "        \n",
    "        rated_matrix = tf.gather_nd(self.item_vectors_2,rated_by_user, batch_dims=0)\n",
    "        \n",
    "        rated_matrix_sum = tf.reduce_sum(rated_matrix,1)\n",
    "        \n",
    "        neigh_vector = tf.multiply(rated_matrix_sum, tf.expand_dims(1/tf.math.sqrt(num_rated_user),1))\n",
    "        \n",
    "        total_vector = neigh_vector + user_vectors_input\n",
    "        \n",
    "        pred = tf.math.reduce_sum(tf.math.multiply(total_vector,item_vectors_input), axis = 1, keepdims = True)\n",
    "        \n",
    "        res = user_bias_input + item_bias_input +  self.global_bias + pred\n",
    "        return (res)\n",
    "\n",
    "    \n",
    "\n",
    "class SVDPP(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SVDPP, self).__init__()\n",
    "        self._supports_ragged_inputs = True #Support ragged tensor\n",
    "        self.svdpp = SVDPP_layer(5, 10000, 10000, l2=0.0001)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.svdpp(inputs)\n",
    "        return (x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.5752639 ]\n",
      " [-0.56866264]\n",
      " [-0.60082906]\n",
      " [-0.56856346]\n",
      " [-0.5675902 ]\n",
      " [-0.57178676]\n",
      " [-0.59123176]\n",
      " [-0.6065353 ]\n",
      " [-0.60107464]\n",
      " [-0.58581024]], shape=(10, 1), dtype=float32)\n",
      "Model: \"svdpp_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "svdpp_layer_4 (SVDPP_layer)  multiple                  170003    \n",
      "=================================================================\n",
      "Total params: 170,003\n",
      "Trainable params: 170,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create ragged feature columns\n",
    "X_with_implicit_features_10 = [ \n",
    "    [X[i,0], \n",
    "     X[i,1], \n",
    "     max(len(rated_by_user[X[i,0]])-1,1), \n",
    "     *[n for n in rated_by_user[X[i,0]] if n != X[i,1]] # Make sure X[i,1] is not in implicit features\n",
    "    ] \n",
    "    for i in range(10)\n",
    "]\n",
    "\n",
    "# Convert to ragged tensor \n",
    "X_with_implicit_features_10_ragged = tf.ragged.constant(X_with_implicit_features_10)\n",
    "\n",
    "\n",
    "\n",
    "model = SVDPP()\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "print(model(X_with_implicit_features_10_ragged))\n",
    "model.summary()\n",
    "\n",
    "# Callback for autostopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_root_mean_squared_error', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ragged feature columns\n",
    "X_with_implicit_features = [ \n",
    "    [X[i,0], \n",
    "     X[i,1], \n",
    "     max(len(rated_by_user[X[i,0]])-1,1), \n",
    "     *[n for n in rated_by_user[X[i,0]] if n != X[i,1]] # Make sure X[i,1] is not in implicit features\n",
    "    ] \n",
    "    for i in range(100000)\n",
    "]\n",
    "\n",
    "X_with_implicit_features_ragged = tf.ragged.constant(X_with_implicit_features) # Convert to ragged tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn's train_test_split doesn't work for ragged tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_implicit_features, y, test_size=0.2, random_state=999)\n",
    "X_train_ragged = tf.ragged.constant(X_train)\n",
    "X_test_ragged = tf.ragged.constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 4s 4ms/step - loss: 10.3975 - root_mean_squared_error: 3.1577 - val_loss: 1.8657 - val_root_mean_squared_error: 1.3357\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 1.6092 - root_mean_squared_error: 1.2342 - val_loss: 1.2902 - val_root_mean_squared_error: 1.0947\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 1.1770 - root_mean_squared_error: 1.0409 - val_loss: 1.1251 - val_root_mean_squared_error: 1.0153\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 1.0533 - root_mean_squared_error: 0.9795 - val_loss: 1.0652 - val_root_mean_squared_error: 0.9872\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 1.0078 - root_mean_squared_error: 0.9586 - val_loss: 1.0193 - val_root_mean_squared_error: 0.9672\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.9668 - root_mean_squared_error: 0.9407 - val_loss: 1.0042 - val_root_mean_squared_error: 0.9634\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.9469 - root_mean_squared_error: 0.9342 - val_loss: 0.9845 - val_root_mean_squared_error: 0.9573\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.9390 - root_mean_squared_error: 0.9339 - val_loss: 0.9669 - val_root_mean_squared_error: 0.9514\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.9288 - root_mean_squared_error: 0.9319 - val_loss: 0.9597 - val_root_mean_squared_error: 0.9507\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.9128 - root_mean_squared_error: 0.9264 - val_loss: 0.9512 - val_root_mean_squared_error: 0.9489\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8989 - root_mean_squared_error: 0.9214 - val_loss: 0.9430 - val_root_mean_squared_error: 0.9467\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8973 - root_mean_squared_error: 0.9226 - val_loss: 0.9379 - val_root_mean_squared_error: 0.9456\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8904 - root_mean_squared_error: 0.9204 - val_loss: 0.9297 - val_root_mean_squared_error: 0.9425\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8841 - root_mean_squared_error: 0.9182 - val_loss: 0.9234 - val_root_mean_squared_error: 0.9398\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8739 - root_mean_squared_error: 0.9133 - val_loss: 0.9212 - val_root_mean_squared_error: 0.9394\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8704 - root_mean_squared_error: 0.9119 - val_loss: 0.9130 - val_root_mean_squared_error: 0.9354\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.8666 - root_mean_squared_error: 0.9100 - val_loss: 0.9039 - val_root_mean_squared_error: 0.9303\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8520 - root_mean_squared_error: 0.9018 - val_loss: 0.8987 - val_root_mean_squared_error: 0.9272\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8383 - root_mean_squared_error: 0.8938 - val_loss: 0.8963 - val_root_mean_squared_error: 0.9256\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8435 - root_mean_squared_error: 0.8965 - val_loss: 0.8916 - val_root_mean_squared_error: 0.9229\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8341 - root_mean_squared_error: 0.8910 - val_loss: 0.8893 - val_root_mean_squared_error: 0.9214\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8235 - root_mean_squared_error: 0.8848 - val_loss: 0.8863 - val_root_mean_squared_error: 0.9195\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8198 - root_mean_squared_error: 0.8824 - val_loss: 0.8824 - val_root_mean_squared_error: 0.9170\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8128 - root_mean_squared_error: 0.8780 - val_loss: 0.8812 - val_root_mean_squared_error: 0.9160\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8103 - root_mean_squared_error: 0.8762 - val_loss: 0.8783 - val_root_mean_squared_error: 0.9140\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.8045 - root_mean_squared_error: 0.8724 - val_loss: 0.8786 - val_root_mean_squared_error: 0.9136\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7902 - root_mean_squared_error: 0.8635 - val_loss: 0.8749 - val_root_mean_squared_error: 0.9109\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7918 - root_mean_squared_error: 0.8638 - val_loss: 0.8743 - val_root_mean_squared_error: 0.9100\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7881 - root_mean_squared_error: 0.8610 - val_loss: 0.8731 - val_root_mean_squared_error: 0.9086\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7818 - root_mean_squared_error: 0.8565 - val_loss: 0.8737 - val_root_mean_squared_error: 0.9083\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7752 - root_mean_squared_error: 0.8521 - val_loss: 0.8718 - val_root_mean_squared_error: 0.9066\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7710 - root_mean_squared_error: 0.8489 - val_loss: 0.8712 - val_root_mean_squared_error: 0.9057\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7715 - root_mean_squared_error: 0.8486 - val_loss: 0.8707 - val_root_mean_squared_error: 0.9048\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7693 - root_mean_squared_error: 0.8466 - val_loss: 0.8716 - val_root_mean_squared_error: 0.9045\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.7659 - root_mean_squared_error: 0.8438 - val_loss: 0.8714 - val_root_mean_squared_error: 0.9039\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.7601 - root_mean_squared_error: 0.8398 - val_loss: 0.8711 - val_root_mean_squared_error: 0.9031\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7603 - root_mean_squared_error: 0.8392 - val_loss: 0.8720 - val_root_mean_squared_error: 0.9030\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7599 - root_mean_squared_error: 0.8383 - val_loss: 0.8727 - val_root_mean_squared_error: 0.9028\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7511 - root_mean_squared_error: 0.8325 - val_loss: 0.8726 - val_root_mean_squared_error: 0.9022\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7440 - root_mean_squared_error: 0.8276 - val_loss: 0.8734 - val_root_mean_squared_error: 0.9021\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7460 - root_mean_squared_error: 0.8283 - val_loss: 0.8755 - val_root_mean_squared_error: 0.9030\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7489 - root_mean_squared_error: 0.8296 - val_loss: 0.8737 - val_root_mean_squared_error: 0.9013\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7464 - root_mean_squared_error: 0.8276 - val_loss: 0.8760 - val_root_mean_squared_error: 0.9023\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7415 - root_mean_squared_error: 0.8241 - val_loss: 0.8756 - val_root_mean_squared_error: 0.9018\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7389 - root_mean_squared_error: 0.8222 - val_loss: 0.8760 - val_root_mean_squared_error: 0.9016\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7411 - root_mean_squared_error: 0.8232 - val_loss: 0.8765 - val_root_mean_squared_error: 0.9015\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7396 - root_mean_squared_error: 0.8218 - val_loss: 0.8755 - val_root_mean_squared_error: 0.9006\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7391 - root_mean_squared_error: 0.8213 - val_loss: 0.8759 - val_root_mean_squared_error: 0.9005\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7474 - root_mean_squared_error: 0.8259 - val_loss: 0.8748 - val_root_mean_squared_error: 0.8997\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7252 - root_mean_squared_error: 0.8120 - val_loss: 0.8756 - val_root_mean_squared_error: 0.8999\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7320 - root_mean_squared_error: 0.8160 - val_loss: 0.8767 - val_root_mean_squared_error: 0.9003\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7334 - root_mean_squared_error: 0.8165 - val_loss: 0.8764 - val_root_mean_squared_error: 0.8998\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7335 - root_mean_squared_error: 0.8163 - val_loss: 0.8765 - val_root_mean_squared_error: 0.8997\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7306 - root_mean_squared_error: 0.8144 - val_loss: 0.8765 - val_root_mean_squared_error: 0.8995\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7336 - root_mean_squared_error: 0.8160 - val_loss: 0.8765 - val_root_mean_squared_error: 0.8993\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7346 - root_mean_squared_error: 0.8163 - val_loss: 0.8762 - val_root_mean_squared_error: 0.8990\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7323 - root_mean_squared_error: 0.8148 - val_loss: 0.8786 - val_root_mean_squared_error: 0.9000\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7294 - root_mean_squared_error: 0.8128 - val_loss: 0.8765 - val_root_mean_squared_error: 0.8986\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7307 - root_mean_squared_error: 0.8134 - val_loss: 0.8786 - val_root_mean_squared_error: 0.8997\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7248 - root_mean_squared_error: 0.8095 - val_loss: 0.8780 - val_root_mean_squared_error: 0.8993\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7260 - root_mean_squared_error: 0.8101 - val_loss: 0.8784 - val_root_mean_squared_error: 0.8993\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7257 - root_mean_squared_error: 0.8098 - val_loss: 0.8784 - val_root_mean_squared_error: 0.8991\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7272 - root_mean_squared_error: 0.8105 - val_loss: 0.8773 - val_root_mean_squared_error: 0.8984\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7272 - root_mean_squared_error: 0.8104 - val_loss: 0.8802 - val_root_mean_squared_error: 0.8998\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7224 - root_mean_squared_error: 0.8072 - val_loss: 0.8780 - val_root_mean_squared_error: 0.8985\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7253 - root_mean_squared_error: 0.8089 - val_loss: 0.8786 - val_root_mean_squared_error: 0.8988\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7240 - root_mean_squared_error: 0.8081 - val_loss: 0.8778 - val_root_mean_squared_error: 0.8982\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7267 - root_mean_squared_error: 0.8096 - val_loss: 0.8780 - val_root_mean_squared_error: 0.8982\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7299 - root_mean_squared_error: 0.8114 - val_loss: 0.8781 - val_root_mean_squared_error: 0.8981\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7307 - root_mean_squared_error: 0.8118 - val_loss: 0.8779 - val_root_mean_squared_error: 0.8980\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7250 - root_mean_squared_error: 0.8082 - val_loss: 0.8787 - val_root_mean_squared_error: 0.8983\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7287 - root_mean_squared_error: 0.8103 - val_loss: 0.8783 - val_root_mean_squared_error: 0.8980\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7278 - root_mean_squared_error: 0.8097 - val_loss: 0.8796 - val_root_mean_squared_error: 0.8986\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7254 - root_mean_squared_error: 0.8081 - val_loss: 0.8787 - val_root_mean_squared_error: 0.8981\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7273 - root_mean_squared_error: 0.8093 - val_loss: 0.8788 - val_root_mean_squared_error: 0.8980\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7243 - root_mean_squared_error: 0.8072 - val_loss: 0.8806 - val_root_mean_squared_error: 0.8989\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7278 - root_mean_squared_error: 0.8094 - val_loss: 0.8794 - val_root_mean_squared_error: 0.8982\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7237 - root_mean_squared_error: 0.8067 - val_loss: 0.8793 - val_root_mean_squared_error: 0.8981\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7275 - root_mean_squared_error: 0.8090 - val_loss: 0.8806 - val_root_mean_squared_error: 0.8987\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.7242 - root_mean_squared_error: 0.8069 - val_loss: 0.8814 - val_root_mean_squared_error: 0.8990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e239ace10>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_ragged, y_train, epochs=100, batch_size = 100, verbose = 1, validation_data = (X_test_ragged, y_test), callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
